<!doctype html>
<html lang="en">

<head>
    <title>Projects - tmralmeida</title>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>


    <link rel="canonical" href="https://getbootstrap.com/docs/4.3/examples/cover/">

    <!-- Bootstrap core CSS -->
     <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="styles/styles.css" rel="stylesheet">
    <link href="styles/projects.css" rel="stylesheet">
    

    <script src="scripts/toggle.js"> </script>
</head>

<body class="text-center">
    <div class="cover-container d-flex w-100 h-100 p-3 mx-auto flex-column">
        <header class="masthead mb-auto">
            <div class="inner">
                <h3 class="masthead-brand">tmralmeida</h3>
                <nav class="nav nav-masthead justify-content-center">
                    <a class="nav-link" href="index.html">Home</a>
                    <a class="nav-link active" href="projects.html">Projects</a>
                    <a class="nav-link" href="publications.html">Publications</a>
                    <a class="nav-link" href="resume.html">Resume</a>
                    <a class="nav-link" href="contacts.html">Contacts</a>
                </nav>
            </div>
        </header>

        <main role="main" class="inner cover">


            <div class="card">
              <h2 class="card-header">bag-of-models</h2>
              <div class="card-body">
                  <h5 class="card-title">Mar 2020 - now</h5>
                  <div class="progress">
                      <div class="progress-bar" role="progressbar" style="width: 25%;" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100">25%</div>
                    </div>
                  <p class="card-text">This is a guide for Deep Learning practitioners. It covers Tensorflow and Pytorch
                  techniques to train the best-known models for a wide-range of fields.</p>
                <button id="read_more_bag" type="button" class="btn btn-primary" data-toggle="modal" data-target="#modal-bag">
                    Continue reading
                </button>
                <div class="modal fade" id="modal-bag" tabindex="-1" role="dialog" aria-labelledby="bag-modal-title" aria-hidden="true">
                  <div class="modal-dialog modal-lg" role="document">
                    <div class="modal-content">
                      <div class="modal-header">
                        <h4 class="modal-title" id="bag-modal-title">bag-of-models Project</h4>
                        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                          <span aria-hidden="true">&times;</span>
                        </button>
                      </div>
                      <div class="modal-body">
                        
                        <p class="describe-projects">
                          This is a guide for Deep Learning practitioners. It covers Tensorflow and Pytorch techniques to train the best-known models for a wide-range of fields. At the beginning
                          of my journey of learning Deep Learning in practice, the most difficult thing for me was filtering out all the information, because every practicioner has one repository
                          and it seems that they have results but their code is too complex for a beginner. Therefore, I started with a <a href="https://www.coursera.org/specializations/tensorflow-in-practice"
                          class="tooltip-test">Tensorflow Specialization</a> and as I was learning, I was doing my test cases for myself. In my opinion, the easiest way to start is with Image Classification because 
                          it does not resort as much as effort as the other fields. The effort here is important, because it is an effort related to the complexity of conceiving the model in practice, so less
                          effort means a more understandable and easier code. Thus, I started to download one dataset (CINIC10), then I tried to replicate the models training that I was studying 
                          through the respective papers (I went from AlexNet to MobileNet). The code is not the most efficient one but it was done by a beginner so I hope that it is clear enough.
                        </p class="describe-projects">
                        <p class="describe-projects">
                          After Image Classification, I wanted to study Object Detection, which seems a trendy Computer Vision task but it was difficult to assimilate all the little tricks behind each 
                          choice of the authors of the most well-known architectures. At the same time, in my work the opportunity of working also in Object Detection arose. So, it was a win-win situation.
                          First, I attend the <a href="https://deeplizard.com/learn/video/v5cngxo4mIg" class="tooltip-test">deeplizard</a> course about Pytorch because I wanted to know all the decent possibilities
                          I had in terms of Deep Learning frameworks. Hence, Pytorch was used to study this Computer Vision task.
                        </p>
                        <p class="describe-projects">
                          Now, you can decide which of the branches of this project you want to check:
                       
                          <div class="btn-group" role="group">
                            <button id="btnGroupDrop1" type="button" class="btn btn-secondary dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                              Fields
                            </button>
                            <div class="dropdown-menu" aria-labelledby="btnGroupDrop1">
                              <a class="dropdown-item" onclick="toggle_modals('#modal-bag', '#modal-classification')">Image Classification</a>
                              <a class="dropdown-item" onclick="toggle_modals('#modal-bag', '#modal-detection')">Object Detection</a>
                              <a class="dropdown-item disabled" href="#">Image Segmentation</a>
                              <a class="dropdown-item disabled" href="#">GANs</a>
                              <a class="dropdown-item disabled" href="#">RNNs</a>
                            </div>
                          </div>
                      </p>
                      </div>
                      <div class="modal-footer">
                        <button id="prev_bag" type="button" class="btn btn-primary" onclick="toggle_modals('#modal-bag', '#modal-faster')">Previous</button>
                        <button type="button" class="btn btn-primary" disabled>Next</button>
                        <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                      </div>
                    </div>
                  </div>
                </div>

              </div>
            </div>

            <!-- Bag of models fields -->
            <!-- Classification -->
            <div class="modal fade" id="modal-classification" tabindex="-1" role="dialog" aria-labelledby="classification-modal-title" aria-hidden="true">
              <div class="modal-dialog modal-lg" role="document">
                <div class="modal-content">
                  <div class="modal-header">
                    <h4 class="modal-title" id="classification-modal-title">Image Classification</h4>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    <p class="describe-projects">
                      First of all, for data loading I used in every model the <a href="https://www.tensorflow.org/guide/data" class="tooltip-test">tf.data module</a>. It allows to create
                      a full pipeline that aggregates: the loading from disk, data augmentation, and batch formation. I did not go too deep in augmentation because the objective at this point
                      would be to practice the models creation and try to understand the various ways of doing it by using Tensorflow2.0. In my opinion, there are three global ways to deploy a 
                      model whose usage depends on the architecture's layout. If the model is straightforward (the most easiest ones) we can use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential"
                      class="tooltip-test">Sequential API</a>; on the other hand, if the model resorts layers concatenation and "parallel operations" (more complex models), we should use the 
                      <a href="https://www.tensorflow.org/guide/keras/functional" class="tooltip-test"> Functional API</a>; finally, if we want a fully-customizable foward 
                      propagation we can use <a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" class="tooltip-test">Model subclassing</a>. 
                    </p>
                    <p class="describe-projects">
                      During this study, I just used the Sequential API for the easiest models and the Functional API for the more complex ones. Therefore, the first three models - AlexNet, ZFNet 
                      and VGG16 - were created the Sequential API due to their simple design. The remaining models - ResNet18, GoogLeNet, Xception and MobileNet - were designed through the Functional
                      API.
                    </p>
                    <p class="describe-projects">
                      Theoretically, it is important to highlight some key points in the history of Convolutional Neural Networks for Image Classification, that are now used or have an influence on
                      the most moder architectures:

                      <ul class="list-group list-group-flush" style="color:black;font-weight:300;">
                        <li class="list-group-item"><b>AlexNet</b> is the first Convolutional Neural Network that obtained a quite important result in the ImageNet challenge;</li>
                        <li class="list-group-item"><b>ZFNet</b> showed how it would be possible to improve the network's layout by visualizing what is going on inside of it;</li>
                        <li class="list-group-item"><b>VGG16</b> showed that deeper convolutional neural networks can be more accurate than shallower networks; </li>
                        <li class="list-group-item">The more layers a neuronal network has, the harder it is to train. Thus, <b>ResNet</b> showed how it is possible to train deep neural network in a simpler fashion by 
                          applying residual blocks with skip connections.</li>
                      </ul> 
                    </p>
                    
                
                    <p class="describe-projects">
                      <b>You can check all notebook at </b><a href="https://github.com/tmralmeida/bag-of-models/tree/master/CNNs/1-Image_Classification" class="tooltip-test">tmralmeida</a>.
                    </p>
                    
                   
                  </div>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-primary" onclick="toggle_modals('#modal-classification', '#modal-detection')">Next</button>
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>

            <!-- Detection -->
            <div class="modal fade" id="modal-detection" tabindex="-1" role="dialog" aria-labelledby="detection-modal-title" aria-hidden="true">
              <div class="modal-dialog modal-lg" role="document">
                <div class="modal-content">
                  <div class="modal-header">
                    <h4 class="modal-title" id="detection-modal-title">Object Detection</h4>
                    <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                      <span aria-hidden="true">&times;</span>
                    </button>
                  </div>
                  <div class="modal-body">
                    
                    
                  </div>
                  <div class="modal-footer">
                    <button id="prev_bag" type="button" class="btn btn-primary" onclick="toggle_modals('#modal-detection', '#modal-classification')">Previous</button>
                    <button type="button" class="btn btn-primary" disabled>Next</button>
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>










            <div class="card">
              <h2 class="card-header">faster-rcnn-data-matrix</h2>
              <div class="card-body">
                  <h5 class="card-title">Mar 2020</h5>
                   <div class="progress">
                      <div class="progress-bar" role="progressbar" style="width: 100%;" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100">Finished</div>
                    </div>
                  <p class="card-text">This work presents an implementation of a Faster R-CNN model to detect Data Matrix. This architecture
                  demonstrated quite accurate and consistent results by...</p>

                <button type="button" class="btn btn-primary" data-toggle="modal" data-target="#modal-faster">
                    Continue reading
                </button>
                <!-- Modal -->
                <div class="modal fade" id="modal-faster" tabindex="-1" role="dialog" aria-labelledby="faster-modal-title" aria-hidden="true">
                  <div class="modal-dialog modal-lg" role="document">
                    <div class="modal-content">
                      <div class="modal-header">
                        <h4 class="modal-title" id="faster-modal-title">faster-rcnn-data-matrix Project</h4>
                        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                          <span aria-hidden="true">&times;</span>
                        </button>
                      </div>
                      <div class="modal-body">
                          <p class="describe-projects">
                              This work presents an implementation of a Faster R-CNN model to detect Data Matrix. This architecture
                              demonstrated quite accurate and consistent results by detecting almost all landmarks throughout the test
                              set.
                          </p>
                          <p class="describe-projects">
                              It arose during my research work at University of Aveiro, Portugal. In this project, I went through
                              every step of training a deep neural network: we collected data (images of this type of landmarks in different environments);
                              we labeled that data through the <a href="https://labelbox.com/" class="tooltip-test">Labelbox app</a>; then, we trained and 
                              evaluated the Faster R-CNN model through the <a href="https://github.com/facebookresearch/detectron2" class="tooltip-test">
                              Detectron2 platform</a>, which is a research platform that contains several state-of-the-art models such as Faster R-CNN, Mask R-CNN, 
                              RetinaNet, and DensePose ready to use. 
                          </p>
                          <p class="describe-projects">
                              <b>Advice:</b> For those who don't have much time to design the architecture, this kind of platforms is totally worth it.
                          </p>
                          <p class="describe-projects">
                            <h5 style="color:black">1. Dataset creation</h5>
                              <p class="describe-projects">
                                The dataset is one of the most important pieces of the overall Machine Learning solution, since each decision of the model is based on 
                                a previous training, which is performed on that data. Therefore, if the training procedure has been compromised, then the inference quality of the model will be worse.
                                Thus, in this stage of the work, we labeled correctly 156 training frames and 224 test images. This distribution of training/test sets
                                is not either the most common one or the most correct one. However, the number of class objects to detect is just one, and, although it
                                is a small patch of the image, it is a pretty distinguishable object from the rest of the image. So, the training set is equally distributed
                                by two different environments: a common laboratory room with several objects spread around and a workshop with machinery. These choices allow to
                                obtain a more representative dataset. Regarding the test set, this is also equally distributed into two different enviroments: a hallway and a different
                                part of the workshop used in the training set.
                              </p>
                              <p class="describe-projects"> 
                                The two images below are 2 samples used in the training set. The left image represents an environment associated to a manufacturing facility and the 
                                right image represents a visually cluttered environment (many different objects) in a laboratory room.
                                <div class="row">
                                  <div class="col">
                                    <img class="img-responsive" src="images/projects/faster-data-matrix/train1.png" style="width: 100%;" alt="image 1 from train set">
                                  </div>
                                  <div class="col">
                                    <img class="img-responsive" src="images/projects/faster-data-matrix/train2.png" style="width: 100%;" alt="image 2 from train set">
                                  </div>
                                </div>
                              </p>
                              <p class="describe-projects">
                               Regarding the test set, two images are shown as examples: from a more visually neat environment (left image) to a more filled and cluttered one (
                                right image). 
                                <div class="row">
                                  <div class="col">
                                    <img class="img-responsive" src="images/projects/faster-data-matrix/test2.png" style="width: 100%" alt="image 1 from test set">
                                  </div>
                                  <div class="col">
                                    <img class="img-responsive" src="images/projects/faster-data-matrix/test1.png" style="width: 100%;" alt="image 2 from test set">
                                  </div>
                                  
                                </div>
                              </p>
                            </p>

                          <p class="describe-projects">
                            <h5 style="color:black">2. Faster R-CNN Training</h5>
                            <p class="describe-projects">
                              We decided to use this architecture because this type of deep neural networks are very performants (in comparison to other object detection architectures) when the 
                              objective is to detect small patches of the image. 
                              Moreover, the system where this neural network would be used (an Automated Guided Vehicle) does not move at high speeds, so the high-latency disadvantage of a proposal 
                              network would not be a problem in this application. 
                              It is worth mentioning that when you are at the phase of choosing which Machine Learning approach to use, you have to take into account the practical
                              application where you are working at (Deep Learning is sometimes overkill for some applications, Machine Learning is much more than just Deep Learning).
                            </p>
                            <p class="describe-projects">
                              The training procedure of a deep neural network can be divided into 3 main steps: data loading, forward propagation and back propagation. The first step in this work 
                              implied to register our dataset in the dataset catalog of Detectron2. This is no more than a function that translates our dataset in a dictionary with certain fields.
                              You can check all these steps in my <a href="https://github.com/tmralmeida/faster-rcnn-data-matrix/blob/master/faster-rcnn-data-matrix.ipynb" class="tooltip-test">notebook</a>.
                              Finally, the second and third steps, Detectron2 makes everything by us, we just need to know how to use their API and choose some hyperparameters such as: batch size, 
                              learning rate, and the number of iterations.  
                            </p>
                          </p>
                          <p class="describe-projects">
                            <h5 style="color:black">3. Faster R-CNN Evaluation</h5>
                            <p class="describe-projects">
                              The evaluation of the model was also performed through the Detectron2 API. To do so, we evaluate our model trough the <a href="http://cocodataset.org/#detection-eval" 
                              class="tooltip-test">COCO metrics</a> (the figure below shows our results).
                            </p>
                            
                            <img class="img-responsive" src="images/projects/faster-data-matrix/results.png" style="width: 60%" alt="results test set">
                            
                            <p class="describe-projects">
                              The most important overall result is 0.876 for AP@0.5. Why? Because 0.5 is a fair value for the IoU threshold, the scales are all and the number maximum of 
                              detections is 100 (a suitable value to match the reality). In addition, the recall is higher than the precision, implying that the number of false positives is 
                              higher than the number of false negatives. This means that the model detects almost all the Data Matrix landmarks, but also detects some other objects that are not. In our
                              system this is preferable since we use a Data Matrix decoder in a further step. So, if the detected object is not a Data Matrix, the decoder would return nothing. 
                              Comparing to the Data Matrix detection provided by <a href="https://pypi.org/project/pylibdmtx/" class="tooltip-test">libdmtx Python library</a>, only 45% of the test 
                              set frames were accurately processed by this classical algorithm, being 40 times slower than the model that we trained in this project. 
                            </p>
                            <p class="describe-projects">
                              Finally, we show a video that demonstrate part of the qualitative results of the test set. The results shown here are not at the normal speed due to the video size 
                              (this is 1fps and our model can achieve 7.4fps).  
                            </p>                            
                              <iframe width="100%" height="315" src="https://www.youtube.com/embed/41Ul3dbbNDw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                          </p>
                          <p class="describe-projects">
                            <b>You can check the repository at </b><a href="https://github.com/tmralmeida/faster-rcnn-data-matrix" class="tooltip-test">tmralmeida</a>.
                          </p>
                        </div>
                      <div class="modal-footer">
                        <button type="button" class="btn btn-primary" disabled>Previous</button>
                        <button type="button" class="btn btn-primary" onclick="toggle_modals('#modal-faster,#modal-bag')">Next</button>
                        <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
            

        </main>

        <footer class="mastfoot mt-auto">
            <div class="inner">
                <p>last update: 01/06/2020</p>
            </div>
        </footer>
    </div>


</body>

</html>